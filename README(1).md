# Analizador LÃ©xico con AutÃ³matas Finitos Deterministas (AFD)

Este proyecto implementa un **analizador lÃ©xico** para un lenguaje tipo *Python*, usando **AutÃ³matas Finitos Deterministas (DFA)** diseÃ±ados y codificados manualmente en **Python**.  
El enfoque es **POO (ProgramaciÃ³n Orientada a Objetos)**: cada tipo de token tiene su propio AFD implementado como una clase independiente.  
Finalmente, un **Lexer** central utiliza estos AFD para recorrer el cÃ³digo fuente y generar la lista de tokens.

---

## âœ… Â¿QuÃ© hace este analizador?
- Lee un archivo de cÃ³digo fuente (ej. `ejemplo.py`).
- Reconoce y emite tokens en el formato solicitado:
  - **Palabras reservadas:** `<palabra,fila,columna>`
  - **Identificadores:** `<id,lexema,fila,columna>`
  - **Enteros:** `<tk_entero,valor,fila,columna>`
  - **Cadenas:** `<tk_cadena,"texto",fila,columna>`
  - **Operadores y sÃ­mbolos:** `<tk_nombre,fila,columna>`
- Ignora **espacios** y **comentarios**.
- Aplica el **principio de subcadena mÃ¡s larga** (ej. `!=` antes que `!`).
- Muestra un **error lÃ©xico** y detiene el anÃ¡lisis al primer caracter invÃ¡lido:
  ```
  >>> Error lÃ©xico(linea:X,posicion:Y)
  ```

---

## âœ… CaracterÃ­sticas principales
âœ” **AFDs implementados como clases**:
- `AFDIdentificador` â†’ Identificadores y palabras reservadas.
- `AFDEntero` â†’ NÃºmeros enteros (con signo opcional).
- `AFDCadena` â†’ Literales de cadena (`"` o `'`).
- `AFDOperador` â†’ Operadores simples y dobles (`==`, `!=`, `<=`, `>=`, `->`, etc.).

âœ” **Lexer modular**:
- Tiene una lista de AFDs y los ejecuta en orden de prioridad.
- Si un AFD reconoce el token, lo emite y avanza.
- Si ninguno lo reconoce, genera error lÃ©xico.

âœ” **Soporte para casos especiales**:
- Punto `.` tokenizado aparte (ej. `90.00.50` â†’ `90`, `.`, `00`, `.`, `50`).
- Comentarios con `#` ignorados.
- Cadenas con `"` o `'`, soporta escapes simples (`\"` y `\'`).

---

## âœ… Requisitos
- **Python 3.x** (probado en 3.8+)
- No requiere librerÃ­as externas.

---

## âœ… Estructura del proyecto
```
ðŸ“‚ proyecto-lexer
 â”œâ”€â”€ lexer_clases.py       # Analizador lÃ©xico implementado con POO
 â”œâ”€â”€ README.md             # Este archivo
 â”œâ”€â”€ ejemplo.py            # Ejemplo de cÃ³digo para probar el lexer
```

---

## âœ… CÃ³mo ejecutar
1. Clona el repositorio o descarga los archivos.
2. Crea un archivo de prueba (ej. `ejemplo.py`):
   ```python
   class Animal:
       def __init__(self, nombre):
           self.nombre = nombre
   ```
3. Ejecuta el analizador:
   ```bash
   python3 lexer_clases.py ejemplo.py
   ```
4. Salida esperada:
   ```
   <class,1,1>
   <id,Animal,1,7>
   <tk_dos_puntos,1,13>
   <def,2,5>
   ...
   ```

---

## âœ… Ejemplo con error lÃ©xico
Archivo:
```
2.5598055while3!=88Â¬56.a
```
Salida:
```
<tk_entero,2,1,1>
<tk_punto,1,2>
<tk_entero,5598055,1,3>
<id,while3,1,10>
<tk_distinto,1,16>
<tk_entero,88,1,18>
>>> Error lÃ©xico(linea:1,posicion:20)
```

---

## âœ… Â¿Por quÃ© usamos AFD?
Porque un **analizador lÃ©xico** es bÃ¡sicamente un conjunto de **autÃ³matas deterministas** que reconocen patrones de tokens.  
Cada token (identificador, nÃºmero, cadena, etc.) tiene su **propio AFD**, y todos estÃ¡n implementados de forma manual siguiendo la lÃ³gica de la funciÃ³n de transiciÃ³n Î´.

---

## âœ… Mejoras posibles
- Soporte para **floats** (nÃºmeros con punto decimal como un solo token).
- Soporte para **cadenas multilÃ­nea** y triple comillas.
- ValidaciÃ³n mÃ¡s avanzada de escapes en cadenas.
- GeneraciÃ³n de **archivo de salida** automÃ¡tico en vez de imprimir en consola.

---

## âœ… Autor
Proyecto desarrollado como parte de la materia **TeorÃ­a de la ComputaciÃ³n** / **Compiladores** (5Â° semestre).  
**Autor:** *[Tu Nombre]*  
**Lenguaje:** Python  
**Tema:** AnÃ¡lisis lÃ©xico con AutÃ³matas Finitos Deterministas.
